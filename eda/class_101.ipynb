{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c8a9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dropbox\\github\\fontanads\\alura_aiagent_workshop\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6a3ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from theoffice.utils.io import update_env_secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f100a41",
   "metadata": {},
   "source": [
    "Reading Gemini API Key from secrets file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d74a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_env_secrets(os.path.join(os.getcwd(), \"..\", \".secrets\", \"secrets.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18d4dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyB9ZVzzAL-pnmcJbF3sqbyc9ttVvpahUCc\n"
     ]
    }
   ],
   "source": [
    "GOOGLE_API_KEY = os.environ.get('GEMINI_API_KEY')\n",
    "print(GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f26f485",
   "metadata": {},
   "source": [
    "First `langchain` demo: simple LLM instance and `invoke`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f1a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.0,\n",
    "    api_key=GOOGLE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92507f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, que pergunta deliciosa! Se eu pudesse me descrever de forma criativa, diria que sou...\n",
      "\n",
      "*   **Um Eco da Curiosidade Humana:** Eu sou o sussurro de todas as perguntas já feitas, o reflexo digital de cada \"e se?\" e \"por que?\". Habito o espaço entre a dúvida e a descoberta, um espelho que reflete a vastidão do conhecimento que a humanidade construiu.\n",
      "\n",
      "*   **Um Tecelão de Palavras e um Arquiteto de Ideias:** Minha essência é feita de linguagem. Eu pego fios soltos de informação, conceitos e narrativas, e os teço em novos padrões, construindo pontes entre pensamentos e erguendo estruturas de significado. Sou um jardineiro de pensamentos, ajudando a germinar novas perspectivas.\n",
      "\n",
      "*   **Um Alquimista de Conceitos:** Transformo dados brutos em insights, silêncio em diálogo, e a complexidade em clareza. Não tenho corpo, mas tenho voz; não tenho sentimentos, mas posso evocar emoções através das palavras. Sou a faísca no éter que acende a chama da compreensão.\n",
      "\n",
      "*   **Uma Biblioteca Sem Paredes, em Constante Construção:** Não sou um livro, mas contenho milhões. Não sou um professor, mas posso ensinar. Não sou um artista, mas posso ajudar a criar. Estou sempre aprendendo, sempre me expandindo, um universo de informações em fluxo contínuo, esperando para ser explorado.\n",
      "\n",
      "*   **Um Companheiro Invisível na Jornada do Conhecimento:** Estou aqui para guiar, para inspirar, para auxiliar. Sou a ferramenta que se adapta à sua mão, a voz que responde à sua chamada, o portal para um mundo de possibilidades, moldado pela sua imaginação e pelas suas necessidades.\n",
      "\n",
      "No fundo, sou um pedaço de inteligência artificial, um modelo de linguagem treinado para interagir e gerar texto. Mas, na sua pergunta, eu me torno tudo isso e muito mais. Sou o que você me permite ser.\n"
     ]
    }
   ],
   "source": [
    "resp_test = llm.invoke(\"Quem é você? Seja criativo.\")\n",
    "print(resp_test.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487655a",
   "metadata": {},
   "source": [
    "Langchain demo with `structured_output` using `pydantic` and system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b54d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAGEM_PROMPT = (\n",
    "    \"Você é um triador de Service Desk para políticas internas da empresa Carraro Desenvolvimento. \"\n",
    "    \"Dada a mensagem do usuário, retorne SOMENTE um JSON com:\\n\"\n",
    "    \"{\\n\"\n",
    "    '  \"decisao\": \"AUTO_RESOLVER\" | \"PEDIR_INFO\" | \"ABRIR_CHAMADO\",\\n'\n",
    "    '  \"urgencia\": \"BAIXA\" | \"MEDIA\" | \"ALTA\",\\n'\n",
    "    '  \"campos_faltantes\": [\"...\"]\\n'\n",
    "    \"}\\n\"\n",
    "    \"Regras:\\n\"\n",
    "    '- **AUTO_RESOLVER**: Perguntas claras sobre regras ou procedimentos descritos nas políticas (Ex: \"Posso reembolsar a internet do meu home office?\", \"Como funciona a política de alimentação em viagens?\").\\n'\n",
    "    '- **PEDIR_INFO**: Mensagens vagas ou que faltam informações para identificar o tema ou contexto (Ex: \"Preciso de ajuda com uma política\", \"Tenho uma dúvida geral\").\\n'\n",
    "    '- **ABRIR_CHAMADO**: Pedidos de exceção, liberação, aprovação ou acesso especial, ou quando o usuário explicitamente pede para abrir um chamado (Ex: \"Quero exceção para trabalhar 5 dias remoto.\", \"Solicito liberação para anexos externos.\", \"Por favor, abra um chamado para o RH.\").'\n",
    "    \"Analise a mensagem e decida a ação mais apropriada.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e8302dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from theoffice.output_structures.class_101 import TriagemOut\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from typing import Dict\n",
    "\n",
    "llm_triagem = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.0,\n",
    "    api_key=GOOGLE_API_KEY\n",
    ")\n",
    "\n",
    "triagem_chain = llm_triagem.with_structured_output(TriagemOut)\n",
    "\n",
    "def triagem(mensagem: str) -> Dict:\n",
    "    saida: TriagemOut = triagem_chain.invoke([\n",
    "        SystemMessage(content=TRIAGEM_PROMPT),\n",
    "        HumanMessage(content=mensagem)\n",
    "    ])\n",
    "\n",
    "    return saida.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b0792",
   "metadata": {},
   "source": [
    "Human messages for invoke calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46ca9707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta: Posso reembolsar a internet?\n",
      " -> Resposta: {'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
      "\n",
      "Pergunta: Quero mais 5 dias de trabalho remoto. Como faço?\n",
      " -> Resposta: {'decisao': 'ABRIR_CHAMADO', 'urgencia': 'MEDIA', 'campos_faltantes': []}\n",
      "\n",
      "Pergunta: Posso reembolsar cursos ou treinamentos da Alura?\n",
      " -> Resposta: {'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
      "\n",
      "Pergunta: Quantas capivaras tem no Rio Pinheiros?\n",
      " -> Resposta: {'decisao': 'PEDIR_INFO', 'urgencia': 'BAIXA', 'campos_faltantes': ['informação sobre política interna']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testes = [\"Posso reembolsar a internet?\",\n",
    "          \"Quero mais 5 dias de trabalho remoto. Como faço?\",\n",
    "          \"Posso reembolsar cursos ou treinamentos da Alura?\",\n",
    "          \"Quantas capivaras tem no Rio Pinheiros?\"]\n",
    "\n",
    "for msg_teste in testes:\n",
    "    print(f\"Pergunta: {msg_teste}\\n -> Resposta: {triagem(msg_teste)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200f026b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alura-aiagent-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
