{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a3ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from theoffice.utils.io import update_env_secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f100a41",
   "metadata": {},
   "source": [
    "Reading Gemini API Key from secrets file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_env_secrets(os.path.join(os.getcwd(), \"..\", \".secrets\", \"secrets.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d4dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.environ.get('GEMINI_API_KEY')\n",
    "# print(GOOGLE_API_KEY)  # DO NOT COMMIT THE PRINTED OUTPUT TO GITHUB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f26f485",
   "metadata": {},
   "source": [
    "First `langchain` demo: simple LLM instance and `invoke`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f1a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.0,\n",
    "    api_key=GOOGLE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92507f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_test = llm.invoke(\"Quem é você? Seja criativo.\")\n",
    "print(resp_test.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487655a",
   "metadata": {},
   "source": [
    "Langchain demo with `structured_output` using `pydantic` and system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAGEM_PROMPT = (\n",
    "    \"Você é um triador de Service Desk para políticas internas da empresa Carraro Desenvolvimento. \"\n",
    "    \"Dada a mensagem do usuário, retorne SOMENTE um JSON com:\\n\"\n",
    "    \"{\\n\"\n",
    "    '  \"decisao\": \"AUTO_RESOLVER\" | \"PEDIR_INFO\" | \"ABRIR_CHAMADO\",\\n'\n",
    "    '  \"urgencia\": \"BAIXA\" | \"MEDIA\" | \"ALTA\",\\n'\n",
    "    '  \"campos_faltantes\": [\"...\"]\\n'\n",
    "    \"}\\n\"\n",
    "    \"Regras:\\n\"\n",
    "    '- **AUTO_RESOLVER**: Perguntas claras sobre regras ou procedimentos descritos nas políticas (Ex: \"Posso reembolsar a internet do meu home office?\", \"Como funciona a política de alimentação em viagens?\").\\n'\n",
    "    '- **PEDIR_INFO**: Mensagens vagas ou que faltam informações para identificar o tema ou contexto (Ex: \"Preciso de ajuda com uma política\", \"Tenho uma dúvida geral\").\\n'\n",
    "    '- **ABRIR_CHAMADO**: Pedidos de exceção, liberação, aprovação ou acesso especial, ou quando o usuário explicitamente pede para abrir um chamado (Ex: \"Quero exceção para trabalhar 5 dias remoto.\", \"Solicito liberação para anexos externos.\", \"Por favor, abra um chamado para o RH.\").'\n",
    "    \"Analise a mensagem e decida a ação mais apropriada.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8302dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from theoffice.output_structures.class_101 import TriagemOut\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from typing import Dict\n",
    "\n",
    "llm_triagem = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.0,\n",
    "    api_key=GOOGLE_API_KEY\n",
    ")\n",
    "\n",
    "triagem_chain = llm_triagem.with_structured_output(TriagemOut)\n",
    "\n",
    "def triagem(mensagem: str) -> Dict:\n",
    "    saida: TriagemOut = triagem_chain.invoke([\n",
    "        SystemMessage(content=TRIAGEM_PROMPT),\n",
    "        HumanMessage(content=mensagem)\n",
    "    ])\n",
    "\n",
    "    return saida.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b0792",
   "metadata": {},
   "source": [
    "Human messages for invoke calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca9707",
   "metadata": {},
   "outputs": [],
   "source": [
    "testes = [\"Posso reembolsar a internet?\",\n",
    "          \"Quero mais 5 dias de trabalho remoto. Como faço?\",\n",
    "          \"Posso reembolsar cursos ou treinamentos da Alura?\",\n",
    "          \"Quantas capivaras tem no Rio Pinheiros?\"]\n",
    "\n",
    "for msg_teste in testes:\n",
    "    print(f\"Pergunta: {msg_teste}\\n -> Resposta: {triagem(msg_teste)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200f026b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alura-aiagent-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
